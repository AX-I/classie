{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Free Music Archive (FMA) Dataset\n",
    "\n",
    "**Note**: Most of the preprocessing segments of this notebook require local installations of the FMA dataset. If you do not have these files installed, please disregard all the annotated code blocks that refer to this and load the .npz files as the data source.\n",
    "\n",
    "The purpose of this notebook is to preprocess and clean the FMA dataset that will be used in `model_training.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code and content contained in this notebook is the original work of Tobey Brizuela and Michael Umeh. This intellectual property is intended solely for educational and non-commercial use as part of the final project for Neural Nets and Deep Learning (CSC413) at the University of Toronto.\n",
    "\n",
    "This material may not be reproduced, distributed, transmitted, displayed, published, or broadcast without the prior written permission of Tobey Brizuela and Michael Umeh. Unauthorized use or reproduction of this content may constitute a violation of copyright law.\n",
    "\n",
    "For inquiries regarding the use of this material, please contact:\n",
    "- Tobey Brizuela: tobey.brizuela@mail.utoronto.ca\n",
    "- Michael Umeh: michael.umeh@mail.utoronto.ca\n",
    "\n",
    "April 14, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required methods and libraries\n",
    "# --------------------------------------------\n",
    "\n",
    "# Note: In order to run this project using CUDA (which is highly recommended!), you must have PyTorch installed with CUDA.\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import itertools\n",
    "\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import myutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "\n",
    "# pip install opencv-python\n",
    "import cv2 as cv\n",
    "\n",
    "# UNUSED imports:\n",
    "# ---------------\n",
    "# from tensorflow.keras import layers, models, optimizers\n",
    "# from tensorflow.keras.layers import Conv2D, Input\n",
    "# from tensorflow.keras.models import Model\n",
    "# from torchvision.models import vgg19\n",
    "# from tensorflow.keras.applications import VGG19\n",
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras import callbacks\n",
    "# from tensorflow.keras import regularizers\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "# from matplotlib import cm\n",
    "# import pylab\n",
    "# from PIL import Image\n",
    "# from matplotlib.pyplot import imshow\n",
    "# from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definitions\n",
    "SPEC_HEIGHT = 216\n",
    "SPEC_WIDTH = 216\n",
    "SPEC_SIZE = 216\n",
    "NUM_GENRES = 16\n",
    "\n",
    "# UNUSED? Directory where mp3 are stored:\n",
    "# -------------------------------\n",
    "# AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "# Raw song data:\n",
    "# --------------\n",
    "# get tracks for small data set\n",
    "# d_size = 'small'\n",
    "# get tracks for medium data set\n",
    "d_size = 'medium'\n",
    "# set the directory path to the correct data set\n",
    "directory_path = 'data/fma_' + d_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Construction and Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load song metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_metadata files installed locally in\n",
    "#       the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "tracks = myutils.load('data/fma_metadata/tracks.csv')\n",
    "genres = myutils.load('data/fma_metadata/genres.csv')\n",
    "features = myutils.load('data/fma_metadata/features.csv')\n",
    "# UNUSED data\n",
    "# echonest = myutils.load('data/fma_metadata/echonest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "selected_tracks = tracks[tracks['set', 'subset'] <= d_size]\n",
    "\n",
    "# select top genre column\n",
    "hottest_genres = selected_tracks[\"track\"][\"genre_top\"]\n",
    "hottest_genres = hottest_genres.to_frame()\n",
    "hottest_genres = hottest_genres.dropna()\n",
    "\n",
    "# get indices\n",
    "ids = hottest_genres.index.values.reshape(-1, 1)\n",
    "# note: track ids for tracks that ONLY have a valid top_genre\n",
    "\n",
    "# Extract categories from categorical column\n",
    "categories = hottest_genres['genre_top'].cat.categories\n",
    "\n",
    "# Convert categories to a dictionary mapping category values to integer indices\n",
    "categories_dict = {category: i for i, category in enumerate(categories)}\n",
    "\n",
    "# convert to integer codes\n",
    "hottest_genres['genre_top'] = hottest_genres['genre_top'].cat.codes\n",
    "\n",
    "# convert to array\n",
    "hottest_genres = np.array(hottest_genres)\n",
    "\n",
    "# create labels data \n",
    "labels = np.zeros((hottest_genres.shape[0], 16))\n",
    "labels[np.arange(hottest_genres.shape[0]), hottest_genres.flatten()] = 1\n",
    "\n",
    "# flattening ids to single list, to make easier to work with\n",
    "flattened_ids = [item for sublist in ids for item in sublist]\n",
    "\n",
    "# filtering the ids out from features\n",
    "selected_features = features.loc[flattened_ids]\n",
    "features_data = np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the tracks that have broken audio data from features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Hard-coded found broken audio tracks for fma_medium dataset...\n",
    "broken_audio_tracks = [316, 977, 6996, 7709, 10675, 13146, 15626, 15627, 15628, 15634, 15836, 16305, 16643, 16959, 20621, 20780, 21988, 23620]\n",
    "\n",
    "# create the mask for features\n",
    "keep_features_mask = np.ones(features_data.shape[0], dtype=bool)\n",
    "keep_features_mask[broken_audio_tracks] = False\n",
    "\n",
    "# create the masks for labels\n",
    "keep_labels_mask = np.ones(labels.shape[0], dtype=bool)\n",
    "keep_labels_mask[broken_audio_tracks] = False\n",
    "\n",
    "# remove broken tracks\n",
    "filtered_features_data = np.delete(features_data, np.where(~keep_features_mask), axis=0)\n",
    "filtered_labels_data = np.delete(labels, np.where(~keep_labels_mask), axis=0)\n",
    "\n",
    "# Prints to verify filters successful\n",
    "print(\"Original features shape:\", features_data.shape)\n",
    "print(\"Filtered features shape:\", filtered_features_data.shape)\n",
    "\n",
    "print(\"Original labels shape:\", labels.shape)\n",
    "print(\"Filtered labels shape:\", filtered_labels_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio-to-Spectrogram Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogrammer(mp3_path, alpha):\n",
    "\n",
    "    print(mp3_path)\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(mp3_path, sr=22050)\n",
    "    except Exception as e:\n",
    "        # return an empty array\n",
    "        return []\n",
    "\n",
    "    # pre-emphasis filter to improve noise to signal ratio    \n",
    "    y = librosa.effects.preemphasis(y, coef=alpha)\n",
    "\n",
    "    # Compute the spectrogram\n",
    "    D = librosa.stft(y)\n",
    "\n",
    "    D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    D_db = cv.resize(D_db, dsize=(SPEC_SIZE, SPEC_SIZE), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "    return D_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "alpha = 0.97\n",
    "image_data = []\n",
    "\n",
    "\n",
    "def build_a_bear(directory_path):\n",
    "    bad_indices = []\n",
    "    bad_index = 0\n",
    "    directory = Path(directory_path)  # Use Path object for directory\n",
    "    for folder in sorted(directory.iterdir()):  # Iterate through folders in sorted order (id order)\n",
    "        if folder.is_dir():\n",
    "            for file_path in sorted(folder.iterdir()):  # Iterate through files in sorted order (id order)\n",
    "                spec_array = spectrogrammer(file_path, alpha)\n",
    "                if np.any(spec_array):\n",
    "                    image_data.append(spec_array)\n",
    "                else:\n",
    "                    bad_indices.append(bad_index)\n",
    "                bad_index += 1\n",
    "    print(bad_indices)\n",
    "\n",
    "build_a_bear(directory_path)\n",
    "\n",
    "# cast the spectrograms into an np.array\n",
    "image_data = np.array(image_data)\n",
    "\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Spectrogram Values Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Function to help normalize a spectrogram to range [0,1]\n",
    "def normalize_spectrogram(spectrogram):\n",
    "    # Rescale values to range [0, 1]\n",
    "    scaled_spectrogram = (spectrogram + 80) / 80.0\n",
    "    return scaled_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNUSED: Storing un-normalized spectrogram data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export the spectrograms array to its own file for safe keeping!\n",
    "\n",
    "# # Specify the directory path for saving\n",
    "# data_directory = 'data'\n",
    "# npz_file_name = 'fma_spectrograms.npz'\n",
    "# npz_file_path = os.path.join(data_directory, npz_file_name)\n",
    "\n",
    "# # Create the directory if it does not exist\n",
    "# os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "# np.savez(npz_file_path, *image_data)\n",
    "\n",
    "# print(f\"Array saved successfully at: {npz_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNUSED: Load un-normalized spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the directory path\n",
    "# data_directory = 'data'\n",
    "# npz_file_name = 'fma_spectrograms.npz'\n",
    "# npz_file_path = os.path.join(data_directory, npz_file_name)\n",
    "\n",
    "# # load the .npz file for use when we want to return to testing!\n",
    "# image_data_load = np.load(npz_file_path)\n",
    "# spectrograms = list(image_data_load.values())\n",
    "# image_data = np.array(spectrograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "normalized_spectrograms = [normalize_spectrogram(spec) for spec in image_data]\n",
    "image_data_new = np.array(normalized_spectrograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the **features and labels** arrays to their own files for safe keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Specify the directory path for saving\n",
    "data_directory = 'data'\n",
    "\n",
    "features_file_name = 'fma_features.npz'\n",
    "features_file_path = os.path.join(data_directory, features_file_name)\n",
    "\n",
    "labels_file_name = 'fma_labels.npz'\n",
    "labels_file_path = os.path.join(data_directory, labels_file_name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "np.savez(features_file_path, *filtered_features_data)\n",
    "\n",
    "print(f\"Features saved successfully at: {features_file_path}\")\n",
    "\n",
    "np.savez(labels_file_path, *filtered_labels_data)\n",
    "\n",
    "print(f\"Labels saved successfully at: {labels_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the **normalized spectrograms** to file for safe keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# NOTE: If you are going to run this preprocessing data construction\n",
    "#       you must have the fma_small and/or fma_medium data installed\n",
    "#       locally in the data folder directory!!!\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "data_directory = 'data'\n",
    "npz_file_name = 'fma_norm_spectrograms.npz'\n",
    "npz_file_path = os.path.join(data_directory, npz_file_name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "np.savez(npz_file_path, *image_data_new)\n",
    "\n",
    "print(f\"Array saved successfully at: {npz_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
